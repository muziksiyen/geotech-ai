# -------------------------------------------------
# app.py â€“ geotech.ai (Ã‡ALIÅžIR! TÃœM SORULARA CEVAP + RÄ°SK + RAPOR)
# -------------------------------------------------
import streamlit as st
import pandas as pd
import PyPDF2
import re
import os
import io
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
from reportlab.lib.styles import getSampleStyleSheet

# LangChain
from langchain_huggingface import HuggingFaceEndpoint

# Token
os.environ["HUGGINGFACEHUB_API_TOKEN"] = st.secrets["HUGGINGFACEHUB_API_TOKEN"]

# AI Model
@st.cache_resource
def get_llm():
    return HuggingFaceEndpoint(
        repo_id="mistralai/Mistral-7B-Instruct-v0.2",
        task="conversational",
        temperature=0.3,
        max_new_tokens=500
    )

llm = get_llm()

# Streamlit
st.set_page_config(page_title="geotech.ai", page_icon="globe", layout="wide")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_report" not in st.session_state:
    st.session_state.last_report = None

st.title("geotech.ai")
st.caption("Veri raporu eklendiÄŸinde OTOMATÄ°K risk analizi + Ek-12 rapor! (TÃ¼m sorulara cevap)")

# Sidebar
with st.sidebar:
    st.header("Veri Raporu YÃ¼kle")
    pdf_file = st.file_uploader("PDF YÃ¼kle", type="pdf")
    
    if pdf_file:
        with st.spinner("Rapor iÅŸleniyor..."):
            # PDF'den metin Ã§Ä±kar
            reader = PyPDF2.PdfReader(pdf_file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() or ""
            
            # Veri Ã§Ä±kar
            depths = re.findall(r'Derinlik\D*(\d+\.?\d*)', text, re.I)
            spt_vals = re.findall(r'SPT\D*(\d+)', text, re.I)
            soil_types = re.findall(r'(Kil|Kum|Ã‡akÄ±l|TÄ±n|Organik)', text, re.I)
            cohesion = re.findall(r'Kohezyon\D*(\d+\.?\d*)', text, re.I)
            friction = re.findall(r'SÃ¼rtÃ¼nme\D*(\d+\.?\d*)', text, re.I)
            
            # EÅžÄ°T UZUNLUK YAP
            max_len = max(len(depths), len(spt_vals), len(soil_types), len(cohesion), len(friction))
            def pad_list(lst, length):
                return lst + ['-'] * (length - len(lst))
            
            depths = pad_list(depths, max_len)
            spt_vals = pad_list(spt_vals, max_len)
            soil_types = pad_list(soil_types, max_len)
            cohesion = pad_list(cohesion, max_len)
            friction = pad_list(friction, max_len)
            
            df = pd.DataFrame({
                'Derinlik (m)': depths,
                'SPT': spt_vals,
                'Zemin Tipi': soil_types,
                'Kohezyon (kPa)': cohesion,
                'SÃ¼rtÃ¼nme AÃ§Ä±sÄ± (Â°)': friction
            })
            
            st.subheader("Ã‡Ä±karÄ±lan Veri")
            st.dataframe(df)
            
            # OTOMATÄ°K RÄ°SK ANALÄ°ZÄ° (CHAT FORMATI!)
            messages = [
                {"role": "user", "content": f"Bu geoteknik veriler iÃ§in likefaksiyon riski, oturma tahmini, taÅŸÄ±ma kapasitesi ve temel Ã¶nerisi nedir?\n{df.to_string()}"}
            ]
            try:
                risk_answer = llm.invoke(messages)
            except Exception as e:
                risk_answer = "AI hatasÄ±: " + str(e)
            
            st.subheader("OTOMATÄ°K RÄ°SK ANALÄ°ZÄ°")
            st.markdown(risk_answer)
            
            # Ek-12 Rapor PDF
            def create_pdf():
                buffer = io.BytesIO()
                doc = SimpleDocTemplate(buffer, pagesize=letter)
                styles = getSampleStyleSheet()
                story = []
                
                story.append(Paragraph("ZEMÄ°N VE TEMEL ETÃœDÃœ RAPORU (EK-12)", styles['Title']))
                story.append(Spacer(1, 12))
                story.append(Paragraph("1. GÄ°RÄ°Åž\nProje: Ã–rnek Proje\nAmaÃ§: Temel tasarÄ±mÄ±", styles['Normal']))
                story.append(Spacer(1, 12))
                
                data = [['Derinlik', 'SPT', 'Zemin', 'Kohezyon', 'SÃ¼rtÃ¼nme']] + df.values.tolist()
                table = Table(data)
                story.append(table)
                
                story.append(Spacer(1, 12))
                story.append(Paragraph(f"2. RÄ°SK ANALÄ°ZÄ°:\n{risk_answer}", styles['Normal']))
                
                doc.build(story)
                buffer.seek(0)
                return buffer.getvalue()
            
            pdf_bytes = create_pdf()
            st.download_button("Ek-12 Rapor PDF Ä°ndir", pdf_bytes, "ek12_rapor.pdf", "application/pdf")
            
            # Son raporu sakla
            st.session_state.last_report = {
                'df': df,
                'risk': risk_answer
            }

# Ana Sohbet
with st.container():
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt := st.chat_input("Sorunu sorâ€¦"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("AI dÃ¼ÅŸÃ¼nÃ¼yor..."):
                # SELAM
                if "selam" in prompt.lower():
                    answer = "Selam! geotech.ai burada. PDF yÃ¼kle, otomatik rapor al! ðŸš€"
                else:
                    # Son rapor varsa baÄŸlam ekle
                    context = ""
                    if st.session_state.last_report:
                        context = f"Son rapor verileri:\n{st.session_state.last_report['df'].to_string()}\nRisk: {st.session_state.last_report['risk']}\n"
                    
                    messages = [
                        {"role": "user", "content": f"{context}Geoteknik sorusu: {prompt}"}
                    ]
                    try:
                        answer = llm.invoke(messages)
                    except Exception as e:
                        answer = "AI hatasÄ±: " + str(e)
                
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
